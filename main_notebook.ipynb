{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from srcs.trainer import Trainer\n",
    "from srcs.utils import instantiate, get_logger, is_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "def train_worker(config):\n",
    "    if is_master():\n",
    "        print(config)\n",
    "    logger = get_logger('train')\n",
    "    # setup data_loader instances\n",
    "    data_loader, valid_data_loader = instantiate(config.data_loader)\n",
    "\n",
    "    # build model. print it's structure and # trainable params.\n",
    "    model = instantiate(config.arch)\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    logger.info(model)\n",
    "    logger.info(f'Trainable parameters: {sum([p.numel() for p in trainable_params])}')\n",
    "\n",
    "    # get function handles of loss and metrics\n",
    "    criterion = instantiate(config.loss, is_func=True)\n",
    "    metrics = [instantiate(met, is_func=True) for met in config['metrics']]\n",
    "\n",
    "    # build optimizer, learning rate scheduler.\n",
    "    optimizer = instantiate(config.optimizer, model.parameters())\n",
    "    lr_scheduler = instantiate(config.lr_scheduler, optimizer)\n",
    "\n",
    "    trainer = Trainer(model, criterion, metrics, optimizer,\n",
    "                      config=config,\n",
    "                      data_loader=data_loader,\n",
    "                      valid_data_loader=valid_data_loader,\n",
    "                      lr_scheduler=lr_scheduler)\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def init_worker(working_dir, config):\n",
    "    # initialize training config\n",
    "    config = OmegaConf.create(config)\n",
    "    config.cwd = working_dir\n",
    "    # prevent access to non-existing keys\n",
    "    OmegaConf.set_struct(config, True)\n",
    "    # start training processes\n",
    "    train_worker(config)\n",
    "\n",
    "\n",
    "@hydra.main(version_base=None, config_path='conf/', config_name='train')\n",
    "def main(config):\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    if config.gpu:\n",
    "        config['n_gpu'] = n_gpu\n",
    "    else:\n",
    "        config['n_gpu'] = 0\n",
    "\n",
    "    working_dir = str(Path.cwd().relative_to(hydra.utils.get_original_cwd()))\n",
    "    if config.resume is not None:\n",
    "        config.resume = hydra.utils.to_absolute_path(config.resume)\n",
    "    config = OmegaConf.to_yaml(config, resolve=True)\n",
    "    init_worker(working_dir, config)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
