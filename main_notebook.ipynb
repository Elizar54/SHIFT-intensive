{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "from srcs.trainer import Trainer\n",
    "from srcs.utils import instantiate, get_logger, is_master\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение на трейн, тест и валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./sign_language_dataset\"\n",
    "\n",
    "ttv_dataset_dit = \"./ttv_dataset/\"\n",
    "train_dir = ttv_dataset_dit + \"train\"\n",
    "test_dir = ttv_dataset_dit + \"test\"\n",
    "val_dir = ttv_dataset_dit + \"validation\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "for class_folder in os.listdir(data_dir):\n",
    "    print(class_folder)\n",
    "    class_path = os.path.join(data_dir, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = os.listdir(class_path)\n",
    "        train_images, test_val_images = train_test_split(images, test_size=0.3, random_state=42)\n",
    "        test_images, val_images = train_test_split(test_val_images, test_size=0.5, random_state=42)\n",
    "\n",
    "        for image in train_images:\n",
    "            shutil.copy(os.path.join(class_path, image), os.path.join(train_dir, f\"{class_folder}_{image}\"))\n",
    "        for image in test_images:\n",
    "            shutil.copy(os.path.join(class_path, image), os.path.join(test_dir, f\"{class_folder}_{image}\"))\n",
    "        for image in val_images:\n",
    "            shutil.copy(os.path.join(class_path, image), os.path.join(val_dir, f\"{class_folder}_{image}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seeds for reproducibility\n",
    "SEED = 123\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "def train_worker(config):\n",
    "    if is_master():\n",
    "        print(config)\n",
    "    logger = get_logger('train')\n",
    "    # setup data_loader instances\n",
    "    data_loader, valid_data_loader = instantiate(config.data_loader)\n",
    "\n",
    "    # build model. print it's structure and # trainable params.\n",
    "    model = instantiate(config.arch)\n",
    "    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    logger.info(model)\n",
    "    logger.info(f'Trainable parameters: {sum([p.numel() for p in trainable_params])}')\n",
    "\n",
    "    # get function handles of loss and metrics\n",
    "    criterion = instantiate(config.loss, is_func=True)\n",
    "    metrics = [instantiate(met, is_func=True) for met in config['metrics']]\n",
    "\n",
    "    # build optimizer, learning rate scheduler.\n",
    "    optimizer = instantiate(config.optimizer, model.parameters())\n",
    "    lr_scheduler = instantiate(config.lr_scheduler, optimizer)\n",
    "\n",
    "    trainer = Trainer(model, criterion, metrics, optimizer,\n",
    "                      config=config,\n",
    "                      data_loader=data_loader,\n",
    "                      valid_data_loader=valid_data_loader,\n",
    "                      lr_scheduler=lr_scheduler)\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def init_worker(working_dir, config):\n",
    "    # initialize training config\n",
    "    config = OmegaConf.create(config)\n",
    "    config.cwd = working_dir\n",
    "    # prevent access to non-existing keys\n",
    "    OmegaConf.set_struct(config, True)\n",
    "    # start training processes\n",
    "    train_worker(config)\n",
    "\n",
    "\n",
    "@hydra.main(version_base=None, config_path='conf/', config_name='train')\n",
    "def main(config):\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    if config.gpu:\n",
    "        config['n_gpu'] = n_gpu\n",
    "    else:\n",
    "        config['n_gpu'] = 0\n",
    "\n",
    "    working_dir = str(Path.cwd().relative_to(hydra.utils.get_original_cwd()))\n",
    "    if config.resume is not None:\n",
    "        config.resume = hydra.utils.to_absolute_path(config.resume)\n",
    "    config = OmegaConf.to_yaml(config, resolve=True)\n",
    "    init_worker(working_dir, config)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
